import sqlite3
import hashlib
import os
import uuid
import logging
from datetime import datetime
from faker import Faker
import openpyxl
from openpyxl import Workbook
from fpdf import FPDF
import PyPDF2
import json
import zipfile
import xml.etree.ElementTree as ET

logger = logging.getLogger(__name__)

class HoneyTokenManager:
    def __init__(self, db_path="honeytokens.db"):
        self.db_path = db_path
        self.fake = Faker()
        self.init_db()

    def init_db(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö —Å –Ω–æ–≤–æ–π –∫–æ–ª–æ–Ω–∫–æ–π event_type"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # –°–æ–∑–¥–∞–µ–º —Ç–∞–±–ª–∏—Ü—É —Ç–æ–∫–µ–Ω–æ–≤ —Å –∫–æ–ª–æ–Ω–∫–æ–π event_type
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS tokens (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                token_guid TEXT UNIQUE NOT NULL,
                token_type TEXT NOT NULL,
                location TEXT NOT NULL,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                triggered INTEGER DEFAULT 0,
                triggered_at TIMESTAMP,
                ip_address TEXT,
                city TEXT,
                country TEXT,
                latitude REAL,
                longitude REAL,
                process_name TEXT,
                process_pid INTEGER,
                username TEXT,
                event_type TEXT DEFAULT 'unknown'  -- –ù–æ–≤–∞—è –∫–æ–ª–æ–Ω–∫–∞ –¥–ª—è —Ç–∏–ø–∞ —Å–æ–±—ã—Ç–∏—è
            )
        ''')
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–æ–ª–æ–Ω–∫–∏ event_type (–¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –ë–î)
        try:
            cursor.execute("PRAGMA table_info(tokens)")
            columns = [column[1] for column in cursor.fetchall()]
            if 'event_type' not in columns:
                cursor.execute("ALTER TABLE tokens ADD COLUMN event_type TEXT DEFAULT 'unknown'")
                logger.info("–î–æ–±–∞–≤–ª–µ–Ω–∞ –∫–æ–ª–æ–Ω–∫–∞ event_type –≤ —Ç–∞–±–ª–∏—Ü—É tokens")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Ç–∞–±–ª–∏—Ü—ã: {e}")
        
        # –°–æ–∑–¥–∞–µ–º —Ç–∞–±–ª–∏—Ü—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –¥–ª—è –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS users (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                username TEXT UNIQUE NOT NULL,
                password_hash TEXT NOT NULL,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        conn.commit()
        conn.close()


    def _calculate_file_hash(self, file_path):
        """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Ö–µ—à–∞ —Ñ–∞–π–ª–∞"""
        try:
            hash_sha256 = hashlib.sha256()
            with open(file_path, "rb") as f:
                for chunk in iter(lambda: f.read(4096), b""):
                    hash_sha256.update(chunk)
            return hash_sha256.hexdigest()
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è —Ö–µ—à–∞ —Ñ–∞–π–ª–∞ {file_path}: {e}")
            return None

    def generate_file_token(self, file_path, content=None, use_faker=True, obfuscate_guid=True):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ñ–∞–π–ª–∞-–ª–æ–≤—É—à–∫–∏ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π —Ä–∞–∑–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤"""
        token_guid = str(uuid.uuid4())
        file_ext = os.path.splitext(file_path)[1].lower()

        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é, –µ—Å–ª–∏ –æ–Ω–∞ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        os.makedirs(os.path.dirname(file_path), exist_ok=True)

        if file_ext == '.pdf':
            self._generate_pdf_token(file_path, token_guid, use_faker, obfuscate_guid)
        elif file_ext in ['.xlsx', '.xls']:
            self._generate_excel_token(file_path, token_guid, use_faker, obfuscate_guid)
        elif file_ext == '.docx':
            self._generate_word_token(file_path, token_guid, use_faker, obfuscate_guid)
        else:
            self._generate_text_token(file_path, token_guid, content, use_faker, obfuscate_guid)

        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        cursor.execute('''
            INSERT INTO tokens (token_guid, token_type, location)
            VALUES (?, ?, ?)
        ''', (token_guid, 'file', file_path))
        conn.commit()
        conn.close()

        logger.info(f"–§–∞–π–ª-–ª–æ–≤—É—à–∫–∞ —Å–æ–∑–¥–∞–Ω: {file_path}, GUID: {token_guid}")
        print(f"‚úÖ –§–∞–π–ª-–ª–æ–≤—É—à–∫–∞ —Å–æ–∑–¥–∞–Ω: {file_path}")
        print(f"   GUID —Ç–æ–∫–µ–Ω–∞: {token_guid}")
        return token_guid

    def _generate_text_token(self, file_path, token_guid, content, use_faker, obfuscate_guid):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ —Ñ–∞–π–ª–∞-–ª–æ–≤—É—à–∫–∏"""
        if use_faker:
            content = f"""CONFIDENTIAL

Company employee data:
Name: {self.fake.name()}
Email: {self.fake.email()}
Phone: {self.fake.phone_number()}
Address: {self.fake.address()}

System credentials:
Username: admin_{self.fake.user_name()}
Password: {self.fake.password(length=12)}

Database connection:
Host: db-{self.fake.word()}.company.com
Port: {self.fake.random_int(min=3000, max=9999)}

Access restricted to authorized personnel only.
"""
        
        if obfuscate_guid:
            hidden_guid = f"\n\n<!-- DocumentID: {token_guid} -->\nRevision: 1.0"
            content += hidden_guid
        else:
            content += f"\n\nToken identifier: {token_guid}\nCreated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"

        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(content)

    def _generate_pdf_token(self, file_path, token_guid, use_faker, obfuscate_guid):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è PDF —Ñ–∞–π–ª–∞-–ª–æ–≤—É—à–∫–∏ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π Unicode"""
        try:
            # –°–æ–∑–¥–∞–µ–º PDF —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π Unicode
            pdf = FPDF()
            
            # –î–æ–±–∞–≤–ª—è–µ–º —à—Ä–∏—Ñ—Ç —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π Unicode (DejaVuSans)
            # –°–Ω–∞—á–∞–ª–∞ –ø–æ–ø—Ä–æ–±—É–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ —à—Ä–∏—Ñ—Ç—ã
            pdf.add_page()
            
            if use_faker:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∞–Ω–≥–ª–∏–π—Å–∫–∏–π —Ç–µ–∫—Å—Ç –¥–ª—è PDF
                content = [
                    "CONFIDENTIAL DOCUMENT",
                    f"Employee Report - {datetime.now().strftime('%d.%m.%Y')}",
                    "",
                    f"Manager: {self.fake.name()}",
                    f"Department: {self.fake.job()}",
                    f"Report Date: {self.fake.date()}",
                    "",
                    "Employee List:"
                ]
                
                for i in range(5):
                    content.append(f"{i+1}. {self.fake.name()} - {self.fake.email()}")
            else:
                content = ["This is a confidential PDF honeytoken document."]

            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —à—Ä–∏—Ñ—Ç
            pdf.set_font("Arial", size=12)
            
            for line in content:
                try:
                    pdf.cell(200, 10, txt=line, ln=True)
                except:
                    # –ï—Å–ª–∏ –µ—Å—Ç—å –ø—Ä–æ–±–ª–µ–º—ã —Å –∫–æ–¥–∏—Ä–æ–≤–∫–æ–π, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π —Ç–µ–∫—Å—Ç
                    pdf.cell(200, 10, txt="Confidential Document - Access Restricted", ln=True)
        
            if obfuscate_guid:
                # –î–æ–±–∞–≤–ª—è–µ–º GUID –≤ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
                pdf.set_title(f"Report_{datetime.now().strftime('%Y%m%d')}")
                pdf.set_author("HR Department")
                pdf.set_subject(f"TokenID: {token_guid}")
            else:
                pdf.cell(200, 10, txt=f"TokenID: {token_guid}", ln=True)

            pdf.output(file_path)
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ PDF: {e}")
            # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Å—Ç–æ–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª –≤–º–µ—Å—Ç–æ PDF
            logger.info(f"–°–æ–∑–¥–∞–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª –≤–º–µ—Å—Ç–æ PDF: {file_path}")
            self._generate_text_token(file_path.replace('.pdf', '.txt'), token_guid, None, use_faker, obfuscate_guid)

    def _generate_excel_token(self, file_path, token_guid, use_faker, obfuscate_guid):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è Excel —Ñ–∞–π–ª–∞-–ª–æ–≤—É—à–∫–∏"""
        wb = Workbook()
        ws = wb.active
        ws.title = "Employees"

        # –ó–∞–≥–æ–ª–æ–≤–∫–∏ –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º
        headers = ["ID", "Full Name", "Position", "Email", "Phone", "Department"]
        ws.append(headers)

        # –î–∞–Ω–Ω—ã–µ
        if use_faker:
            for i in range(10):
                row = [
                    i + 1,
                    self.fake.name(),
                    self.fake.job(),
                    self.fake.email(),
                    self.fake.phone_number(),
                    self.fake.word().capitalize()
                ]
                ws.append(row)
        else:
            ws.append([1, "Test Employee", "Manager", "test@company.com", "+79990000000", "IT"])

        if obfuscate_guid:
            # –°–∫—Ä—ã–≤–∞–µ–º GUID –≤ —Å–∫—Ä—ã—Ç–æ–π —è—á–µ–π–∫–µ
            ws['Z100'] = token_guid
            ws['Z100'].font = openpyxl.styles.Font(color="FFFFFF")  # –ë–µ–ª—ã–π —Ç–µ–∫—Å—Ç
        else:
            ws.append(["", f"TokenID: {token_guid}"])

        wb.save(file_path)

    def _generate_word_token(self, file_path, token_guid, use_faker, obfuscate_guid):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∞–ª—å–Ω–æ–≥–æ Word –¥–æ–∫—É–º–µ–Ω—Ç–∞-–ª–æ–≤—É—à–∫–∏"""
        try:
            from docx import Document
            from docx.shared import Inches
            from docx.enum.text import WD_ALIGN_PARAGRAPH
            
            doc = Document()
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
            title = doc.add_heading('CONFIDENTIAL BUSINESS PLAN', 0)
            title.alignment = WD_ALIGN_PARAGRAPH.CENTER
            
            # –û—Å–Ω–æ–≤–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
            doc.add_paragraph(f"Company: {self.fake.company()}")
            doc.add_paragraph(f"Date: {datetime.now().strftime('%Y-%m-%d')}")
            doc.add_paragraph(f"Author: {self.fake.name()}")
            doc.add_paragraph(f"Document ID: BP-{self.fake.random_number(digits=6)}")
            doc.add_paragraph("")
            
            # Executive Summary
            doc.add_heading('EXECUTIVE SUMMARY', level=1)
            doc.add_paragraph(self.fake.paragraph(nb_sentences=5))
            doc.add_paragraph("")
            
            # Market Analysis
            doc.add_heading('MARKET ANALYSIS', level=1)
            market_content = [
                f"‚Ä¢ Target Market: {self.fake.catch_phrase()}",
                f"‚Ä¢ Market Size: ${self.fake.random_number(digits=3)} million",
                f"‚Ä¢ Growth Rate: {self.fake.random_int(min=5, max=25)}% annually",
                f"‚Ä¢ Key Competitors: {self.fake.company()}, {self.fake.company()}"
            ]
            for item in market_content:
                doc.add_paragraph(item)
            doc.add_paragraph(self.fake.paragraph(nb_sentences=3))
            doc.add_paragraph("")
            
            # Financial Projections
            doc.add_heading('FINANCIAL PROJECTIONS', level=1)
            financial_data = [
                f"Year 1 Revenue: ${self.fake.random_number(digits=7):,}",
                f"Year 2 Revenue: ${self.fake.random_number(digits=7):,}",
                f"Year 3 Revenue: ${self.fake.random_number(digits=8):,}",
                f"Projected Profit Margin: {self.fake.random_int(min=15, max=40)}%"
            ]
            for item in financial_data:
                doc.add_paragraph(item)
            doc.add_paragraph("")
            
            # Growth Strategy
            doc.add_heading('GROWTH STRATEGY', level=1)
            doc.add_paragraph(self.fake.paragraph(nb_sentences=6))
            doc.add_paragraph("")
            
            # Risk Assessment
            doc.add_heading('RISK ASSESSMENT', level=1)
            risks = [
                f"‚Ä¢ Market Risk: {self.fake.sentence()}",
                f"‚Ä¢ Operational Risk: {self.fake.sentence()}",
                f"‚Ä¢ Financial Risk: {self.fake.sentence()}"
            ]
            for risk in risks:
                doc.add_paragraph(risk)
            doc.add_paragraph("")
            
            # Confidential Notice
            confidential = doc.add_paragraph()
            confidential.alignment = WD_ALIGN_PARAGRAPH.CENTER
            confidential.add_run("CONFIDENTIAL AND PROPRIETARY").bold = True
            
            notice = doc.add_paragraph()
            notice.alignment = WD_ALIGN_PARAGRAPH.CENTER
            notice.add_run("This document contains trade secrets and confidential information of ")
            notice.add_run(f"{self.fake.company()}").bold = True
            notice.add_run(".")
            
            warning = doc.add_paragraph()
            warning.alignment = WD_ALIGN_PARAGRAPH.CENTER
            warning.add_run("Unauthorized access, copying, or distribution is strictly prohibited.").bold = True
            
            # –î–æ–±–∞–≤–ª—è–µ–º GUID –≤ –¥–æ–∫—É–º–µ–Ω—Ç (—Å–∫—Ä—ã—Ç–æ –∏–ª–∏ —è–≤–Ω–æ)
            if not obfuscate_guid:
                doc.add_paragraph(f"Document Token: {token_guid}")
            else:
                # –î–æ–±–∞–≤–ª—è–µ–º —Å–∫—Ä—ã—Ç—ã–π GUID –≤ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
                self._add_guid_to_word_metadata(file_path, token_guid, doc)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–æ–∫—É–º–µ–Ω—Ç
            doc.save(file_path)
            logger.info(f"–°–æ–∑–¥–∞–Ω Word –¥–æ–∫—É–º–µ–Ω—Ç: {file_path}")
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ Word –¥–æ–∫—É–º–µ–Ω—Ç–∞: {e}")
            # Fallback - —Å–æ–∑–¥–∞–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª
            self._generate_text_token(file_path, token_guid, None, use_faker, obfuscate_guid)

    def _add_guid_to_word_metadata(self, file_path, token_guid, doc):
        """–î–æ–±–∞–≤–ª—è–µ—Ç GUID –≤ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ Word –¥–æ–∫—É–º–µ–Ω—Ç–∞"""
        try:
            # –°–Ω–∞—á–∞–ª–∞ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –¥–æ–∫—É–º–µ–Ω—Ç
            doc.save(file_path)
            
            # –ó–∞—Ç–µ–º –æ—Ç–∫—Ä—ã–≤–∞–µ–º –∫–∞–∫ zip –∏ –º–æ–¥–∏—Ñ–∏—Ü–∏—Ä—É–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            with zipfile.ZipFile(file_path, 'a') as docx_zip:
                # –ß–∏—Ç–∞–µ–º core.xml
                core_xml = docx_zip.read('docProps/core.xml')
                root = ET.fromstring(core_xml)
                
                # –ù–∞—Ö–æ–¥–∏–º –∏–ª–∏ —Å–æ–∑–¥–∞–µ–º –ø–æ–ª–µ subject
                subject_elem = None
                for elem in root:
                    if 'subject' in elem.tag:
                        subject_elem = elem
                        break
                
                if subject_elem is None:
                    # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π —ç–ª–µ–º–µ–Ω—Ç subject
                    ns = {'cp': 'http://schemas.openxmlformats.org/package/2006/metadata/core-properties'}
                    subject_elem = ET.Element('{http://schemas.openxmlformats.org/package/2006/metadata/core-properties}subject')
                    root.append(subject_elem)
                
                subject_elem.text = f"Business Plan - TokenID: {token_guid}"
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±—Ä–∞—Ç–Ω–æ
                docx_zip.writestr('docProps/core.xml', ET.tostring(root, encoding='unicode'))
                
        except Exception as e:
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –¥–æ–±–∞–≤–∏—Ç—å GUID –≤ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ Word: {e}")
            # –î–æ–±–∞–≤–ª—è–µ–º GUID –∫–∞–∫ —Å–∫—Ä—ã—Ç—ã–π —Ç–µ–∫—Å—Ç –≤ –∫–æ–Ω–µ—Ü –¥–æ–∫—É–º–µ–Ω—Ç–∞
            doc.add_paragraph(f"Reviewer: {self.fake.name()} - ID: {token_guid}")

    def check_token_triggered(self, token_guid):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞, —Å—Ä–∞–±–æ—Ç–∞–ª –ª–∏ —Ç–æ–∫–µ–Ω"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        cursor.execute('SELECT triggered FROM tokens WHERE token_guid = ?', (token_guid,))
        result = cursor.fetchone()
        conn.close()
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º 0 –µ—Å–ª–∏ –∑–∞–ø–∏—Å—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –∏–ª–∏ triggered=0
        if result is None:
            logger.debug(f"–¢–æ–∫–µ–Ω {token_guid} –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –ë–î")
            return 0
        return result[0] if result else 0

    def mark_token_triggered(self, token_guid, ip=None, process_info=None, event_type='modify'):
        """–ü–æ–º–µ—Ç–∏—Ç—å —Ç–æ–∫–µ–Ω –∫–∞–∫ —Å—Ä–∞–±–æ—Ç–∞–≤—à–∏–π —Å —É–∫–∞–∑–∞–Ω–∏–µ–º —Ç–∏–ø–∞ —Å–æ–±—ã—Ç–∏—è"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            logger.debug(f"–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ç–æ–∫–µ–Ω–∞ {token_guid}: event_type={event_type}, ip={ip}")
            
            update_data = [1, datetime.now(), event_type]  # –î–æ–±–∞–≤–ª–µ–Ω event_type
            update_fields = "triggered = ?, triggered_at = ?, event_type = ?"
            
            if ip:
                update_fields += ", ip_address = ?"
                update_data.append(ip)
                logger.info(f"–£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω IP –¥–ª—è —Ç–æ–∫–µ–Ω–∞ {token_guid}: {ip}")
            else:
                logger.warning(f"IP –∞–¥—Ä–µ—Å –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω –¥–ª—è —Ç–æ–∫–µ–Ω–∞ {token_guid}")
            
            if process_info:
                update_fields += ", process_name = ?, process_pid = ?, username = ?"
                update_data.extend([
                    process_info.get('name', 'Unknown'),
                    process_info.get('pid', 0),
                    process_info.get('username', 'Unknown')
                ])
        
            update_data.append(token_guid)
            
            cursor.execute(f'''
                UPDATE tokens 
                SET {update_fields}
                WHERE token_guid = ?
            ''', update_data)
            
            rows_updated = cursor.rowcount
            conn.commit()
            
            if rows_updated > 0:
                logger.warning(f"Honey token {token_guid} –±—ã–ª –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω! IP: {ip}, –¢–∏–ø: {event_type}, –û–±–Ω–æ–≤–ª–µ–Ω–æ —Å—Ç—Ä–æ–∫: {rows_updated}")
                print(f"üö® –¢–†–ï–í–û–ì–ê: Honey token {token_guid} –±—ã–ª –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω! IP: {ip}, –¢–∏–ø: {event_type}")
            else:
                logger.error(f"–¢–æ–∫–µ–Ω {token_guid} –Ω–µ –Ω–∞–π–¥–µ–Ω –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏!")
                print(f"‚ùå –û–®–ò–ë–ö–ê: –¢–æ–∫–µ–Ω {token_guid} –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –ë–î!")
            
        except sqlite3.Error as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ë–î –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ —Ç–æ–∫–µ–Ω–∞ {token_guid}: {e}")
        finally:
            if conn:
                conn.close()

    def update_token_geo(self, token_guid, geo_data):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≥–µ–æ–¥–∞–Ω–Ω—ã—Ö —Ç–æ–∫–µ–Ω–∞"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            cursor.execute('''
                UPDATE tokens 
                SET city = ?, country = ?, latitude = ?, longitude = ?
                WHERE token_guid = ?
            ''', (
                geo_data.get('city'), 
                geo_data.get('country'), 
                geo_data.get('lat'), 
                geo_data.get('lng'), 
                token_guid
            ))
            conn.commit()
            logger.info(f"–ì–µ–æ–¥–∞–Ω–Ω—ã–µ –æ–±–Ω–æ–≤–ª–µ–Ω—ã –¥–ª—è —Ç–æ–∫–µ–Ω–∞ {token_guid}")
        except sqlite3.Error as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ë–î –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ –≥–µ–æ–¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ç–æ–∫–µ–Ω–∞ {token_guid}: {e}")
        finally:
            if conn:
                conn.close()

    def get_active_file_tokens(self):
        """–ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ –∞–∫—Ç–∏–≤–Ω—ã–µ (–Ω–µ—Ç—Ä–∏–≥–≥–µ—Ä–Ω—É—Ç—ã–µ) —Ñ–∞–π–ª–æ–≤—ã–µ —Ç–æ–∫–µ–Ω—ã"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            cursor.execute("SELECT token_guid, location FROM tokens WHERE token_type = 'file' AND triggered = 0")
            tokens = cursor.fetchall()
            return tokens
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∞–∫—Ç–∏–≤–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤: {e}")
            return []
        finally:
            if conn:
                conn.close()

    def get_all_tokens(self):
        """–ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ —Ç–æ–∫–µ–Ω—ã (–¥–ª—è –æ—Ç–ª–∞–¥–∫–∏)"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            cursor.execute("SELECT * FROM tokens")
            tokens = cursor.fetchall()
            return tokens
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –≤—Å–µ—Ö —Ç–æ–∫–µ–Ω–æ–≤: {e}")
            return []
        finally:
            if conn:
                conn.close()

    def get_triggered_tokens_today(self):
        """–ü–æ–ª—É—á–∏—Ç—å —Ç–æ–∫–µ–Ω—ã, —Å—Ä–∞–±–æ—Ç–∞–≤—à–∏–µ —Å–µ–≥–æ–¥–Ω—è (–±–µ–∑–æ–ø–∞—Å–Ω–∞—è –≤–µ—Ä—Å–∏—è)"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            cursor.execute('''
                SELECT * FROM tokens 
                WHERE triggered = 1 AND DATE(triggered_at) = DATE('now')
            ''')
            tokens = cursor.fetchall()
            return tokens
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å–µ–≥–æ–¥–Ω—è—à–Ω–∏—Ö —Ç–æ–∫–µ–Ω–æ–≤: {e}")
            return []
        finally:
            if conn:
                conn.close()

    def generate_trap_tokens(self, original_path, levels=2):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –ª–æ–≤—É—à–µ–∫ –ø–æ—Å–ª–µ —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏—è (–º–∞–∫—Å–∏–º—É–º levels)"""
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª
            if not os.path.exists(original_path):
                logger.warning(f"–û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {original_path}")
                return []
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ñ–∞–π–ª –≤—Ä–µ–º–µ–Ω–Ω—ã–º
            if self._is_temporary_file(original_path):
                logger.warning(f"–ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –ª–æ–≤—É—à–µ–∫: {original_path}")
                return []
            
            base_name = os.path.splitext(os.path.basename(original_path))[0]
            ext = os.path.splitext(original_path)[1].lower()
            directory = os.path.dirname(original_path)
            
            trap_tokens = []
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è –ª–∏ —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –ª–æ–≤—É—à–µ–∫
            supported_extensions = ['.txt', '.pdf', '.docx', '.xlsx', '.xls']
            if ext not in supported_extensions:
                logger.warning(f"–§–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞ {ext} –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –ª–æ–≤—É—à–µ–∫")
                return []
            
            # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –ª–æ–≤—É—à–∫–∏
            existing_traps = self.count_existing_traps(original_path)
            if existing_traps >= levels:
                logger.info(f"–î–ª—è —Ñ–∞–π–ª–∞ {original_path} —É–∂–µ —Å–æ–∑–¥–∞–Ω–æ {existing_traps} –ª–æ–≤—É—à–µ–∫, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤—ã—Ö")
                return []
            
            traps_to_create = min(levels - existing_traps, levels)
            
            for i in range(traps_to_create):
                # –°–æ–∑–¥–∞–µ–º –∏–º—è —Ñ–∞–π–ª–∞-–ª–æ–≤—É—à–∫–∏
                trap_name = f"backup_{base_name}_v{i+1+existing_traps}{ext}"
                trap_path = os.path.join(directory, trap_name)
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ —É–∂–µ —Ç–∞–∫–æ–π —Ñ–∞–π–ª
                if os.path.exists(trap_path):
                    logger.debug(f"–õ–æ–≤—É—à–∫–∞ —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {trap_path}")
                    continue
                
                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –Ω–æ–≤—ã–π —Ç–æ–∫–µ–Ω
                trap_guid = self.generate_file_token(
                    trap_path,
                    use_faker=True,
                    obfuscate_guid=True
                )
                trap_tokens.append((trap_guid, trap_path))
                
                logger.info(f"–°–æ–∑–¥–∞–Ω–∞ –ª–æ–≤—É—à–∫–∞: {trap_path}, GUID: {trap_guid}")
            
            logger.info(f"–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {len(trap_tokens)} –ª–æ–≤—É—à–µ–∫ –¥–ª—è {original_path}")
            return trap_tokens
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ª–æ–≤—É—à–µ–∫ –¥–ª—è {original_path}: {e}")
            return []
    
    def count_existing_traps(self, original_file_path):
        """–ü–æ–¥—Å—á–µ—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –ª–æ–≤—É—à–µ–∫ –¥–ª—è –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Ñ–∞–π–ª–∞"""
        try:
            base_name = os.path.splitext(os.path.basename(original_file_path))[0]
            ext = os.path.splitext(original_file_path)[1].lower()
            directory = os.path.dirname(original_file_path)
            
            if not os.path.exists(directory):
                return 0
            
            trap_count = 0
            for filename in os.listdir(directory):
                if filename.startswith(f"backup_{base_name}_v") and filename.endswith(ext):
                    trap_count += 1
            
            return trap_count
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–¥—Å—á–µ—Ç–∞ –ª–æ–≤—É—à–µ–∫: {e}")
            return 0
    
    def _is_temporary_file(self, file_path):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ñ–∞–π–ª –≤—Ä–µ–º–µ–Ω–Ω—ã–º"""
        filename = os.path.basename(file_path)
        
        # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã Office
        if filename.startswith('~$') or filename.startswith('.~'):
            return True
        
        # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ–º .tmp
        if filename.endswith('.tmp'):
            return True
        
        # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–µ —Ñ–∞–π–ª—ã
        if filename.startswith('~') or filename.startswith('._'):
            return True
        
        return False

    def safe_get_token_field(self, token, index, default=None):
        """–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ –ø–æ–ª—è —Ç–æ–∫–µ–Ω–∞ –ø–æ –∏–Ω–¥–µ–∫—Å—É"""
        try:
            if token and len(token) > index:
                value = token[index]
                return value if value is not None else default
            return default
        except (IndexError, TypeError, AttributeError) as e:
            logger.debug(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –ø–æ–ª—è {index} —Ç–æ–∫–µ–Ω–∞: {e}")
            return default

    def get_database_structure(self):
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # –ü–æ–ª—É—á–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ç–∞–±–ª–∏—Ü—ã
            cursor.execute("PRAGMA table_info(tokens)")
            columns = cursor.fetchall()
            
            # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            cursor.execute("SELECT COUNT(*) FROM tokens")
            total = cursor.fetchone()[0]
            cursor.execute("SELECT COUNT(*) FROM tokens WHERE triggered = 1")
            triggered = cursor.fetchone()[0]
            cursor.execute("SELECT COUNT(*) FROM tokens WHERE token_type = 'file'")
            files = cursor.fetchone()[0]
            
            # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å—Ä–∞–±–æ—Ç–∞–≤—à–∏—Ö —Ç–æ–∫–µ–Ω–∞—Ö —Å IP
            cursor.execute("SELECT COUNT(*) FROM tokens WHERE triggered = 1 AND ip_address IS NOT NULL")
            with_ip = cursor.fetchone()[0]
            
            return {
                'columns': columns,
                'stats': {
                    'total': total,
                    'triggered': triggered,
                    'active': total - triggered,
                    'files': files,
                    'triggered_with_ip': with_ip
                }
            }
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –ë–î: {e}")
            return None
        finally:
            if conn:
                conn.close()

    def cleanup_old_tokens(self, days=30):
        """–û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö —Å—Ä–∞–±–æ—Ç–∞–≤—à–∏—Ö —Ç–æ–∫–µ–Ω–æ–≤"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            cursor.execute('''
                DELETE FROM tokens 
                WHERE triggered = 1 AND triggered_at < DATE('now', ?)
            ''', (f'-{days} days',))
            deleted_count = cursor.rowcount
            conn.commit()
            logger.info(f"–£–¥–∞–ª–µ–Ω–æ {deleted_count} —Å—Ç–∞—Ä—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤ (—Å—Ç–∞—Ä—à–µ {days} –¥–Ω–µ–π)")
            return deleted_count
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ —Å—Ç–∞—Ä—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤: {e}")
            return 0
        finally:
            if conn:
                conn.close()

    def get_token_by_guid(self, token_guid):
        """–ü–æ–ª—É—á–∏—Ç—å —Ç–æ–∫–µ–Ω –ø–æ GUID"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            cursor.execute("SELECT * FROM tokens WHERE token_guid = ?", (token_guid,))
            token = cursor.fetchone()
            return token
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ç–æ–∫–µ–Ω–∞ {token_guid}: {e}")
            return None
        finally:
            if conn:
                conn.close()

    def get_triggered_tokens_with_geo(self):
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ä–∞–±–æ—Ç–∞–≤—à–∏–µ —Ç–æ–∫–µ–Ω—ã —Å –≥–µ–æ–¥–∞–Ω–Ω—ã–º–∏"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            cursor.execute('''
                SELECT * FROM tokens 
                WHERE triggered = 1 AND latitude IS NOT NULL AND longitude IS NOT NULL
            ''')
            tokens = cursor.fetchall()
            return tokens
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ç–æ–∫–µ–Ω–æ–≤ —Å –≥–µ–æ–¥–∞–Ω–Ω—ã–º–∏: {e}")
            return []
        finally:
            if conn:
                conn.close()

    def get_token_by_file_path(self, file_path):
        """–ü–æ–ª—É—á–∏—Ç—å —Ç–æ–∫–µ–Ω –ø–æ –ø—É—Ç–∏ –∫ —Ñ–∞–π–ª—É"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ—á–Ω–æ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –ø—É—Ç–∏
            cursor.execute("SELECT * FROM tokens WHERE location = ?", (file_path,))
            token = cursor.fetchone()
            
            return token
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ç–æ–∫–µ–Ω–∞ –ø–æ –ø—É—Ç–∏ {file_path}: {e}")
            return None
        finally:
            if conn:
                conn.close()

    def get_tokens_by_folder(self, folder_path):
        """–ü–æ–ª—É—á–∏—Ç—å —Ç–æ–∫–µ–Ω—ã –ø–æ –ø–∞–ø–∫–µ"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            cursor.execute("SELECT * FROM tokens WHERE location LIKE ?", (f"{folder_path}%",))
            tokens = cursor.fetchall()
            return tokens
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ç–æ–∫–µ–Ω–æ–≤ –ø–æ –ø–∞–ø–∫–µ {folder_path}: {e}")
            return []
        finally:
            if conn:
                conn.close()            

    def export_tokens_to_json(self, file_path="tokens_export.json"):
        """–≠–∫—Å–ø–æ—Ä—Ç –≤—Å–µ—Ö —Ç–æ–∫–µ–Ω–æ–≤ –≤ JSON —Ñ–∞–π–ª"""
        try:
            tokens = self.get_all_tokens()
            tokens_data = []
            
            for token in tokens:
                token_data = {
                    'id': self.safe_get_token_field(token, 0),
                    'guid': self.safe_get_token_field(token, 1),
                    'type': self.safe_get_token_field(token, 2),
                    'location': self.safe_get_token_field(token, 3),
                    'created_at': self.safe_get_token_field(token, 4),
                    'triggered': bool(self.safe_get_token_field(token, 5, 0)),
                    'triggered_at': self.safe_get_token_field(token, 6),
                    'ip_address': self.safe_get_token_field(token, 7),
                    'city': self.safe_get_token_field(token, 8),
                    'country': self.safe_get_token_field(token, 9),
                    'latitude': self.safe_get_token_field(token, 10),
                    'longitude': self.safe_get_token_field(token, 11),
                    'process_name': self.safe_get_token_field(token, 12),
                    'process_pid': self.safe_get_token_field(token, 13),
                    'username': self.safe_get_token_field(token, 14)
                }
                tokens_data.append(token_data)
            
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(tokens_data, f, indent=2, ensure_ascii=False, default=str)
            
            logger.info(f"–¢–æ–∫–µ–Ω—ã —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã –≤ {file_path}")
            return True
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞ —Ç–æ–∫–µ–Ω–æ–≤: {e}")
            return False

    def get_token_statistics(self):
        """–ü–æ–ª—É—á–∏—Ç—å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ —Ç–æ–∫–µ–Ω–∞–º"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            stats = {}
            
            # –û—Å–Ω–æ–≤–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            cursor.execute("SELECT COUNT(*) FROM tokens")
            stats['total'] = cursor.fetchone()[0]
            
            cursor.execute("SELECT COUNT(*) FROM tokens WHERE triggered = 1")
            stats['triggered'] = cursor.fetchone()[0]
            
            cursor.execute("SELECT COUNT(*) FROM tokens WHERE triggered = 0")
            stats['active'] = cursor.fetchone()[0]
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–∏–ø–∞–º
            cursor.execute("SELECT token_type, COUNT(*) FROM tokens GROUP BY token_type")
            stats['by_type'] = dict(cursor.fetchall())
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –¥–Ω—è–º
            cursor.execute('''
                SELECT DATE(created_at), COUNT(*) 
                FROM tokens 
                GROUP BY DATE(created_at) 
                ORDER BY DATE(created_at) DESC 
                LIMIT 7
            ''')
            stats['created_last_7_days'] = dict(cursor.fetchall())
            
            # –¢–æ–ø IP –∞–¥—Ä–µ—Å–æ–≤
            cursor.execute('''
                SELECT ip_address, COUNT(*) 
                FROM tokens 
                WHERE ip_address IS NOT NULL 
                GROUP BY ip_address 
                ORDER BY COUNT(*) DESC 
                LIMIT 10
            ''')
            stats['top_ips'] = dict(cursor.fetchall())
            
            # –ì–µ–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            cursor.execute("SELECT COUNT(*) FROM tokens WHERE city IS NOT NULL")
            stats['with_geo'] = cursor.fetchone()[0]
            
            return stats
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")
            return {}
        finally:
            if conn:
                conn.close()

# –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏
def setup_database_backup(db_path, backup_dir="backups"):
    """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –±—ç–∫–∞–ø–∞ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
    try:
        os.makedirs(backup_dir, exist_ok=True)
        backup_file = os.path.join(backup_dir, f"honeytokens_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}.db")
        
        import shutil
        shutil.copy2(db_path, backup_file)
        logger.info(f"–°–æ–∑–¥–∞–Ω –±—ç–∫–∞–ø –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö: {backup_file}")
        return backup_file
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –±—ç–∫–∞–ø–∞: {e}")
        return None
def delete_folder_tokens(self, folder_path):
    """–£–¥–∞–ª–µ–Ω–∏–µ –≤—Å–µ—Ö —Ç–æ–∫–µ–Ω–æ–≤ –≤ —É–∫–∞–∑–∞–Ω–Ω–æ–π –ø–∞–ø–∫–µ"""
    try:
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # –£–¥–∞–ª—è–µ–º —Ç–æ–∫–µ–Ω—ã –ø–æ –ø—É—Ç–∏ –ø–∞–ø–∫–∏
        cursor.execute("DELETE FROM tokens WHERE location LIKE ?", (f"{folder_path}%",))
        deleted_count = cursor.rowcount
        conn.commit()
        
        logger.info(f"–£–¥–∞–ª–µ–Ω–æ {deleted_count} —Ç–æ–∫–µ–Ω–æ–≤ –∏–∑ –ø–∞–ø–∫–∏ {folder_path}")
        return deleted_count
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è —Ç–æ–∫–µ–Ω–æ–≤ –ø–∞–ø–∫–∏ {folder_path}: {e}")
        return 0
    finally:
        if conn:
            conn.close()

def get_tokens_in_folder(self, folder_path):
    """–ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ —Ç–æ–∫–µ–Ω—ã –≤ —É–∫–∞–∑–∞–Ω–Ω–æ–π –ø–∞–ø–∫–µ"""
    try:
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # –ü–æ–ª—É—á–∞–µ–º —Ç–æ–∫–µ–Ω—ã –ø–æ –ø—É—Ç–∏ –ø–∞–ø–∫–∏
        cursor.execute("SELECT * FROM tokens WHERE location LIKE ?", (f"{folder_path}%",))
        tokens = cursor.fetchall()
        
        return tokens
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ç–æ–∫–µ–Ω–æ–≤ –∏–∑ –ø–∞–ø–∫–∏ {folder_path}: {e}")
        return []
    finally:
        if conn:
            conn.close()
# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
if __name__ == "__main__":
    import json
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    manager = HoneyTokenManager()
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –ë–î
    structure = manager.get_database_structure()
    if structure:
        print("üìä –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö:")
        for col in structure['columns']:
            print(f"  {col[1]} ({col[2]})")
        print(f"\nüìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
        print(f"  –í—Å–µ–≥–æ —Ç–æ–∫–µ–Ω–æ–≤: {structure['stats']['total']}")
        print(f"  –ê–∫—Ç–∏–≤–Ω—ã—Ö: {structure['stats']['active']}")
        print(f"  –°—Ä–∞–±–æ—Ç–∞–≤—à–∏—Ö: {structure['stats']['triggered']}")
        print(f"  –§–∞–π–ª–æ–≤—ã—Ö: {structure['stats']['files']}")
        print(f"  –°—Ä–∞–±–æ—Ç–∞–≤—à–∏—Ö —Å IP: {structure['stats']['triggered_with_ip']}")
    
    # –°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤
    print("\nüß™ –°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤...")
    
    # –§–∞–π–ª–æ–≤—ã–π —Ç–æ–∫–µ–Ω
    test_file_token = manager.generate_file_token("test_document.pdf")
    print(f"üìÑ –°–æ–∑–¥–∞–Ω —Ñ–∞–π–ª–æ–≤—ã–π —Ç–æ–∫–µ–Ω: {test_file_token}")
    
    # –¢–µ–∫—Å—Ç–æ–≤—ã–π —Ç–æ–∫–µ–Ω
    test_text_token = manager.generate_file_token("test_secret.txt")
    print(f"üìù –°–æ–∑–¥–∞–Ω —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ç–æ–∫–µ–Ω: {test_text_token}")
    
    # Word —Ç–æ–∫–µ–Ω
    test_word_token = manager.generate_file_token("test_business_plan.docx")
    print(f"üìù –°–æ–∑–¥–∞–Ω Word —Ç–æ–∫–µ–Ω: {test_word_token}")
    
    # –†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    stats = manager.get_token_statistics()
    print(f"\nüìä –†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
    print(json.dumps(stats, indent=2, ensure_ascii=False, default=str))
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –±—ç–∫–∞–ø–∞
    backup_file = setup_database_backup("honeytokens.db")
    if backup_file:
        print(f"üíæ –°–æ–∑–¥–∞–Ω –±—ç–∫–∞–ø: {backup_file}")